---
title: "数据结构与算法"
shortTitle: "数据结构与算法"
description: "数据结构与算法"
icon: ""
author: 
  name: gzw
  url: 
  email: 1627121193@qq.com
isOriginal: false
date: 2022-02-01
category: 
- "算法"
tag:
- "算法"
sticky: 999
star: true
article: true
timeline: true,
dir:
  text: "数据结构与算法"
  icon: ""
  collapsible: true
  index: true
  comment: true
headerDepth: 3
index: true
order: 2
copy:
  triggerWords: 100
  disableCopy: false
  disableSelection: false
feed:
  title: "数据结构与算法"
  description: "数据结构与算法"
  author:
    name: gzw
    email: 1627121193@qq.com
---





# 数据结构与算法

[[toc]]

## 什么是算法？

算法是对特定问题求解步骤的一种描述，它是指令的优先序列，其中每一条指令表示一个或多个操作，此外，一个算法还有以下五个重要特性：

- 有穷性
- 确定性
- 可行性
- 输入
- 输出

**一个好的算法应该具有：**

- 正确性
- 健壮性
- 可读性
- 效率与地存储量需求

**算法效率的度量：**

- 事后统计的方法
- 事前分析估算的方法

**高级语言所消耗的时间取决于：**

- 依据的算法采用何种策略
- 问题的规模
- 书写程序的语言
- 编译程序所产生的机器代码的质量
- 机器指令运行的速度

**相关名词：**

- 时间复杂度
- 频度：语句重复执行的次数
- 空间复杂度
- 常用的时间复杂度所耗费的时间从小到大依次是：`O(1) < O(logn) < O(n) < O(nlogn) < O(n^2) < O(n^3) < O(2^n) < O(n!) < O(n^n)`

<br/>



## 时空复杂度

:::相关文章

[算法时空复杂度分析实用指南](https://mp.weixin.qq.com/s?__biz=MzAxODQxMDM0Mw==&mid=2247496738&idx=1&sn=2c7d16c8b0ee64d8101abb35e06b08cc&scene=21#wechat_redirect)

:::



### 时间复杂度

时间复杂度依次增大：

1. O(1) 常数复杂度
2. O(log n) 对数复杂度
3. O(n) 线性复杂度
4. O(n log n) 线性对数复杂度
5. O(n^2) 平方复杂度
6. O(n^3) 立方复杂度
7. O(2^n) 指数复杂度
8. O(n!) 阶乘

需要注意的是，这个排序并不是绝对的，因为不同算法在不同情况下的时间复杂度可能会有所不同。例如，某些问题可能存在一种 O(n^2) 的算法和一种 O(n log n) 的算法，但在实际运行中，O(n^2) 的算法可能比 O(n log n) 的算法更快。因此，在选择算法时，不仅要考虑时间复杂度，还要考虑其他因素，如空间复杂度、算法实现的难易程度、输入数据规模等。



### NP 难问题

NP难问题和非NP难问题是计算机科学中的两个重要概念。

NP（Nondeterministic Polynomial）指非确定性多项式时间，是指一类问题的时间复杂度为O(2^n)或O(n^k)，其中n是问题规模，k是一个常数。这类问题的特点是可以在多项式时间内验证一个解的正确性，但是要在多项式时间内求出一个解则非常困难，因此这类问题被认为是非常困难的。如果一个问题可以在多项式时间内求解，则称为P问题。

NP难问题是指所有NP问题都可以在多项式时间内规约到该问题。也就是说，如果一个NP难问题可以在多项式时间内求解，则所有的NP问题都可以在多项式时间内求解。目前还没有找到一种有效的方法来求解NP难问题，因此这类问题被认为是无法在多项式时间内求解的。

非NP难问题则是指所有NP问题都无法在多项式时间内规约到该问题。也就是说，这类问题不属于NP问题，可以在多项式时间内求解。比如，排序、查找、最短路径等问题都是非NP难问题。

需要注意的是，非NP难问题并不一定是容易求解的问题，它只是与NP问题不同，可以在多项式时间内求解。





## 八大数据结构

- 数组（Array）
- 链表（LinkedList）
- 队列（Queue）
- 栈（Stack）
- 堆（Heap）
- 散列表（Hash）
- 树（Tree）
- 图（Grap）



### 数组与链表

1. 请介绍一下数组和链表的区别？
2. 请实现一个数组或链表的基本操作，例如插入、删除、查找等。
3. 如何对一个数组或链表进行排序？
4. 如何在一个数组或链表中找到第K个最大或最小的元素？
5. 如何判断一个链表是否有环？如何找到链表中环的起点？
6. 如何合并两个有序数组或链表？
7. 如何在一个数组或链表中删除重复的元素？
8. 如何反转一个链表？
9. 如何判断两个链表是否相交？如何找到两个链表相交的点？
10. 如何实现一个LRU Cache（最近最少使用缓存）？



### 散列表

1. 散列表是一种用于存储键值对的数据结构，其中键是通过散列函数计算出的哈希值，值可以是任意类型的数据。
2. 散列表的特点是可以实现快速的查找、插入和删除操作，时间复杂度通常为O(1)。
3. 散列冲突是指两个不同的键计算出的哈希值相同的情况。常见的解决散列冲突的方法包括开放地址法和链表法等。其中开放地址法包括线性探测、二次探测和双重散列等技术。
4. 选择散列函数需要考虑散列值的分布和计算速度等因素。常见的散列函数包括除留余数法、平方取中法、FNV哈希等。
5. 实现散列表可以使用数组和链表等数据结构。数组实现的散列表也被称为哈希表，可以根据键的哈希值计算出在数组中的索引位置。链表实现的散列表则是将哈希冲突的元素放在同一个链表中。
6. 散列表的性能和负载因子相关，负载因子越小，散列表的性能越好。通常当负载因子大于0.7时，需要对散列表进行扩容操作。
7. 在使用散列表时需要注意哈希函数的选择和冲突解决方法的实现，以及散列表的扩容和缩容等问题。





### 树

什么是树：

1. 树是一种非线性的数据结构，由节点和边组成，每个节点可以有多个子节点。
2. 树的基本操作包括插入、删除和查找等。插入和删除节点通常需要重构树的结构以保证树的性质。
3. 二叉树是一种特殊的树结构，每个节点最多有两个子节点。二叉树可以通过中序遍历、前序遍历和后序遍历来遍历整个树。
4. 二叉搜索树是一种二叉树，满足左子树的所有节点的值小于根节点的值，右子树的所有节点的值大于根节点的值。二叉搜索树可以用于排序和快速查找等场景。
5. 树的遍历分为深度优先遍历和广度优先遍历两种。其中深度优先遍历包括前序遍历、中序遍历和后序遍历，广度优先遍历包括层次遍历。
6. 平衡二叉树是一种高度平衡的二叉搜索树，保证了插入、删除和查找操作的时间复杂度均为O(logN)。常见的平衡二叉树包括AVL树和红黑树等。
7. 堆是一种特殊的树结构，通常用于实现优先队列等场景。堆分为最大堆和最小堆两种，最大堆的根节点是整个堆中的最大值，最小堆的根节点是整个堆中的最小值。常见的堆实现包括二叉堆和斐波那契堆等。

常见的树的分类：

1. 二叉树：每个节点最多有两个子节点的树，包括普通二叉树、满二叉树和完全二叉树等。
2. 平衡树：树的左右子树高度差不超过一个固定值的树，例如AVL树、红黑树、B树等。
3. 二叉搜索树：左子树的所有节点值小于当前节点，右子树的所有节点值大于当前节点的二叉树。
4. Trie树（字典树）：一种树形结构，用于处理字符串匹配问题，例如前缀匹配和字符串检索等。

常见的树问题和算法包括：

1. 遍历：前序遍历、中序遍历、后序遍历、层次遍历等。
2. 建树：从已知的数据结构（例如数组、链表）构造树形结构。
3. 查找：查找树中是否存在某个节点，常见算法有二叉搜索树、AVL树、红黑树等。
4. 插入、删除：在树中插入或删除一个节点，常见算法有二叉搜索树的插入、删除操作、AVL树、红黑树等的平衡操作。
5. 应用：树的应用十分广泛，例如 Huffman 编码、LCA（最近公共祖先）问题、构造最小生成树、构造最短路径树等。

总之，树作为一种重要的数据结构，在算法和数据结构领域有广泛的应用，了解树的分类和相关算法是非常有必要的。





### 图

图相关的问题：

1. 什么是图？
2. 图有哪些基本操作？
3. 图的遍历有哪些算法？
4. 如何实现最短路径算法？
5. 如何实现最小生成树算法？
6. 什么是拓扑排序？
7. 什么是连通分量？

相关技巧：

1. 图是由节点和边组成的非线性数据结构，用于描述各种实际问题中的关系和联系。
2. 图的基本操作包括插入节点、删除节点、插入边和删除边等。图的存储方式通常有邻接矩阵和邻接表两种。
3. 图的遍历算法包括深度优先搜索和广度优先搜索两种。深度优先搜索和广度优先搜索的区别在于搜索的顺序不同。
4. 最短路径算法是用于求解两个节点之间最短路径的算法，常见的最短路径算法包括Dijkstra算法和Bellman-Ford算法等。
5. 最小生成树算法是用于求解无向带权图中连接所有节点的最小权重边集合的算法，常见的最小生成树算法包括Prim算法和Kruskal算法等。
6. 拓扑排序是对有向无环图进行排序的算法，用于确定各个节点之间的依赖关系。
7. 连通分量是指无向图中任意两个节点之间有路径相连的最大子图。连通分量算法常用于社交网络、群体分析等领域。

图的经典问题包括：

1. 最短路径：找出图中两个节点之间的最短路径。
   - Dijkstra算法：适用于边的权重为非负数的情况。
   - Bellman-Ford算法：适用于边的权重可能为负数的情况。
   - Floyd算法：可以求解图中任意两点之间的最短路径，但时间复杂度较高。
2. 拓扑排序：对有向无环图进行排序，使得每个顶点的前驱都排在它的后面。
   - Kahn算法：基于贪心思想，每次选择入度为0的节点进行排序。
   - 深度优先搜索（DFS）：基于递归思想，对有向图进行深度优先搜索，并在回溯时将节点加入到结果列表中。
3. 最小生成树：找出连接图中所有节点的最小权重边的集合。
   - Prim算法：基于贪心思想，每次选择权重最小的边并将其连接的节点加入生成树中。
   - Kruskal算法：基于并查集的思想，每次选择权重最小的边并判断其是否与已经加入的边形成环。
4. 最大流：找出从源节点到汇节点的最大流量。
   - Ford-Fulkerson算法：基于增广路径的思想，每次找到一条从源节点到汇节点的增广路径，并更新路径上的流量。
   - Edmonds-Karp算法：在Ford-Fulkerson算法的基础上，使用BFS来查找增广路径，以获得更快的运行速度。

除了上述算法外，还有很多其他的图算法，如欧拉路径、哈密顿回路、最小顶点覆盖等，都是非常重要的图算法。



#### 拓扑排序

将有向无环图排序，排序后所有节点的指向都是同一方向的。如果一幅有向图中存在环，是无法进行拓扑排序的，因为肯定做不到所有箭头方向一致；反过来，如果一幅图是「有向无环图」，那么一定可以进行拓扑排序。



#### DFS

> 回溯算法就是 DFS



#### BFS

BFS 相对 DFS 的最主要的区别是：**BFS 找到的路径一定是最短的，但代价就是空间复杂度比 DFS 大很多**

BFS 一般用于找最短路径，其他情况常用 DFS





### 有序表

可以实现有序表的结构（各种实现时间复杂度都是 O(logN)）：

1. AVL 树（平衡性要求最严苛；维护着高度信息，平衡标准是左右子树的高度差不超过 1）
2. Size Balance 树（常用，改写难度小；维护着节点数信息，平衡标准是「每棵树的大小」不小于其「兄弟的子树大小」）
3. 红黑树（维护着关于自己的平衡树的信息，相比上面两个最复杂，调整太复杂一般不用）
4. 跳表（Skip List）

补充：

- 搜索二叉树默认没有重复值，出现重复值可以存储在节点内部
- 拥有「左旋」与「右旋」操作的搜索二叉树是其具有平衡性的前提，红黑、AVL、SB 树都是用了不同的规定，即规定搜索二叉树怎么左旋或右旋，来实现的有着不同平衡性的树，三者的增删改查（同搜索二叉树的增删改查，只是操作完成之后需要判断是否需要重新平衡）操作如何调整全部一样，但是判断违规的条件不一样
- 维持搜索二叉树的平衡关键在于实现 Rebalance 函数，即由具体的实现指定在什么时机进行怎么样的旋转操作
- AVL 树在删除节点后，会从替代节点的父节点开始检查树的平衡性（这是删除操作的平衡性检查时机）
- AVL 树四种调整类型的含义：
  - LL：左孩子左子树过长，左子树需要左旋
  - RR：右孩子右子树过长，右子树需要右旋
  - LR：左孩子右子树过长，左子树根节点需要调整到整棵树的根节点（先左旋再右旋）
  - RL：右孩子左子树过长，右子树根节点需要调整到整棵树的根节点（先右旋再左旋）
- SB 树四种调整类型的含义：
  - LL：某左节点左孩子规模大于兄弟右节点的规模，该左节点需要先右旋，右旋后需要看参与调整的节点是否变化，变化则继续递归调整
  - RR：某右节点右孩子规模大于兄弟左节点的规模，该右节点需要先左旋，左旋后需要看参与调整的节点是否变化，变化则继续递归调整
  - LR：某左节点右孩子规模大于兄弟右节点的规模，该右孩子需要先左旋再右旋变为根节点，之后需要看参与调整的节点是否变化，变化则继续递归调整
  - RL：某右节点左孩子规模大于兄弟左节点的规模，该左孩子需要先右旋再左旋变为根节点，之后需要看参与调整的节点是否变化，变化则继续递归调整
- 红黑树定义的规则：
  1. 每个节点不是「红」就是「黑」
  2. 头节点和叶节点（最底层的节点，不是没有左右孩子的节点），必须为黑
  3. 任何两个红节点不能相邻
  4. 任意节点出发，要求到叶节点的路径上，黑节点的数量一样（这一点最重要）
- 从红黑树的规则可以发现：
  - 从根节点出发，到叶节点最长的路径为，红黑交替的路径；最短的路径为全黑的路径
  - 但是由于存在第四条规则，所以最长与最短路径的节点数量不会相差超过两倍
- 跳表要求：
  - 传入的 Key 必须可以比较，默认的头节点拥有最小的 Key
  - 节点维护「键值对」以及指向之后节点的（多或单）链表或数组指针，这些指针一般不会全部使用
  - 某一个节点可以有多少个指针与节点本身完全无关，因为是随机生成的指针个数（0.5 的概率为 0，0.5 的概率为 1，只有为 0 才停止增加指针数量），每个节点的指针索引可以称为第几层
  - 跳表中不同节点相同层从小到大单向相连，因为一个节点是否有指针完全通过上述的随机方式生成，所以每一层相连的节点数从高到低是依次增加的，即顶层最少，底层最多
  - 进行增删改查操作时，从顶层开始操作，如果节点值小于需要操作的节点值，就继续寻找，直到遇到比需要操作节点的大的才停止，这样就可以找到最终进行操作的位置
  - 因为每一层指针都是以 1/2 概率生成的，所以当节点数量够大时，从最高层到最底层看，构建的结构就类似完全二叉树，且具有一定搜索功能

















## 八大常用算法思想

算法可以分成两类：

- 明确知道这么算的流程
- 明确知道这么尝试的流程

树形结构几乎贯穿了所有算法思想，许多问题也能转换成具有多个子问题的树状结构



### 1.枚举/穷举

> 穷举或说枚举就是列举「全部可能性」

涉及的问题：

- 待解问题的「可能解/候选解」的筛选条件
- 「可能解」之间的影响
- 穷举「可能解」的代价
- 穷举「可能解」的方式

注意：大部分枚举不可用的场景是由于「可能解」的数量过多，虽然枚举法可能不能帮助我们「解决问题」，但是有助于帮助我们「理解问题」



#### 穷举法优化

1. 减少搜索空间：当问题的搜索空间非常大时，可以采用一些方法来缩小搜索空间，例如剪枝和启发式搜索等。
2. 优化算法设计：通过优化算法设计来减少不必要的计算，例如使用适当的数据结构、算法等。
3. 利用并行计算：当问题可以并行计算时，可以使用并行计算技术来加速穷举法的计算。
4. 避免重复计算：当搜索过程中有许多重复的计算时，可以通过缓存计算结果或者使用记忆化搜索等方法来避免重复计算，从而提高效率。
5. 采用随机化算法：当穷举法无法高效处理问题时，可以考虑采用一些随机化算法来解决问题，例如随机化搜索和遗传算法等。
6. 合理设计数据结构：当问题中包含多个数据结构时，可以通过合理设计数据结构来减少不必要的计算，从而提高效率。



#### 剪枝

剪枝算法有许多不同的形式，其中一些常见的包括：

- α-β 剪枝算法：在博弈树搜索中，α-β 剪枝算法可以通过评估局面的价值，来减少搜索的深度和宽度，从而提高搜索效率。
- 约束满足问题剪枝算法：在约束满足问题中，剪枝算法可以通过检查约束条件，来排除无效的状态节点，从而缩小搜索空间。
- 分支限界剪枝算法：在搜索树中，分支限界剪枝算法可以通过评估每个状态节点的下界，来排除与下界不相交的状态节点，从而减少搜索空间。



#### 启发式算法

启发式算法是一种以启发式信息为指导的搜索算法，它可以在搜索过程中尽快找到可能的最优解，从而提高搜索效率。启发式算法常用于解决NP难问题、优化问题等。

常见的启发式算法包括：

- A*算法：A*算法是一种基于启发式函数的搜索算法，它通过评估每个状态节点的估价函数来指导搜索过程，从而在搜索过程中尽快找到最优解。
- 爬山算法：爬山算法是一种局部搜索算法，它通过不断搜索周围的状态节点，来找到当前最优解，然后继续搜索周围的状态节点，直到找到全局最优解。
- 遗传算法：遗传算法是一种基于生物进化的优化算法，它通过模拟自然选择、交叉和变异等过程，来搜索最优解。





### 2.递推

> 用「已知」推导「未知」—— 逐次逐步推到获取结果，每次「递」是「非回归迭代」

涉及的问题：

- 「递」的含义是逐次、逐步
- 机器涉及到递推时，能处理的是「重复性」的推理
- 「递推」是一个较大的范畴





### 3.递归

> 与递推相似，但是每次「递」是「回归迭代」，直至跳出回归获取结果

本质是把问题分解成规模更小的同类问题

递归问题的时间复杂度计算方式：**⼦问题个数乘以解决⼀个⼦问题需要的时间**

递归一般时间复杂度和空间复杂度都稍大（与不使用递归的解法相比），非必要时尽量避免





### 4.分治

> 分而治之，核心就两步 —— 为什么分及怎么分？怎么治及治后如何？

涉及的问题：

- 分治是一种向下管理的思想，将复杂问题简化为简单的子问题，再通过子问题的解构建复杂问题的解
- 实际应用中常常使用「自顶向下」或「自底向上」求解





### 5.动态规划

> 也需要将复杂问题分解，但是子问题往往不是独立于其他问题的，此时可以把解看作是前 n 个子问题的「总结」，不是简单的「叠加」，也即在大多数情况下要把非独立子问题转化成独立子问题的形式

涉及的问题：

- 缓存思想：处理过程中分为不同的处理阶段，期间要需要记录下前面问题的解，起到缓存的作用
- 状态：需要找到变化的状态再做进一步分析
- 选择：每个阶段需要做出一定的决策
- 动态规划主要就是解决多阶段的决策问题，注意！没有统一的处理方法

动态规划的三大要素：

- 最优子结构（无后效性）：体现了分治法的思想，但是分治法中并不一定存在这一点
- 重叠子问题：缓存实现的关键点
- 状态转移方程：关键在于「如何改变状态」和「如何选择」

**动态规划问题的⼀般形式就是求最值**。

**求解动态规划的核心问题是穷举中找最值，这里的穷举是指优化后带缓存的穷举**。

- 动态规划的「穷举」是存在「重叠子问题的」，如果直接用「暴力穷举」，效率会极其低下

- 因此需要使用「备忘录」或者说「DP Table」来优化穷举的过程，避免不必要的计算

这里的 DP 或说缓存只是一种思想，有很多不同的表现形式，只要能做到避免重复不必要的子问题即可，DP TABLE 的表现形式有：函数、数组、链表等



#### 最优子结构

- 最优子结构之间必须是「独立的」，不独立就必须寻找其他的「重叠子问题」
- 最优子结构一般都是在求最值；最优子结构并不是动态规划独有的一种性质，能求最值的问题大部分都具有这个性质，但是如果一个问题需要求最值，就可以往动态规划的方向思考



#### 重叠子问题

- 寻找重叠子问题的最直接方法就是画出「递归树」
- 重叠子问题有时候是在找到「最优子结构」和「状态转移方程」后考虑的，因为需要找出重叠部分优化暴力解



#### 状态转移

注意：只有列出正确的「状态转移方程」才能正确地「穷举」，而这部分也是最难的

动态规划一般来说求解方向都是「自底向上」，即动态规划一般都是脱离了递归，改用自底向上的迭代完成，但是也有使用自顶向下的递归实现

某些动态规划问题还可以使用「状态压缩」进行优化

**三要素：**

1. 状态
2. 选择
3. Base case



#### 暴力递归到动态规划

不是所有暴力递归都能转成动态规划，但是动态规划都来自暴力递归

**常见的4种尝试模型：**

1. 从左往右的尝试模型.
2. 范围上的尝试模型
3. 多样本位置全对应的尝试模型
4. 寻找业务限制的尝试模型



#### 树形 DP 套路

1. 以某个节点 x 为头节点，分析答案有哪些「可能性」，并且这种分析是以 x 的左子树、右子树、x 整棵树的角度来考虑的
2. 根据第一步的可能性分析，列出所有需要的信息
3. 合并第二部的信息，构造包含所有这些信息的 Info 类，对左子树和右子树提出相同的需求
4. 设计递归函数，递归函数是处理以 x 为头节点的情况下的答案；设计包含设计递归的 basecase，并且默认直接获取左子树和右子树的所有信息，获取信息后将之前分析的所有可能性整合，最后再构造当前这一层递归应该需要返回的信息

```java
/**
 * 求出二叉树上两个节点的最大距离
 * 树形 dp 的递归套路
 */
public class MaxDistance {
    public static class Node {
        public int value;
        public Node left;
        public Node right;

        public Node(int value) {
            this.value = value;
        }
    }
    public static class Info {
        public int maxDistance;
        public int height;
        public Info(int maxDistance, int height) {
            this.maxDistance = maxDistance;
            this.height = height;
        }
    }
    public static int maxDistance(Node head) {
        return process(head).maxDistance;
    }
    public static Info process(Node head) {
        if (head == null) {
            return new Info(0, 0);
        }
        Info left = process(head.left);
        Info right = process(head.right);
        int p1 = left.maxDistance;
        int p2 = right.maxDistance;
        int p3 = left.height + 1 + right.height;
        int maxDistance = Math.max(p1, Math.max(p2, p3));
        int height = Math.max(left.height, right.height) + 1;
        return new Info(maxDistance, height);
    }
}
```





### 6.贪心算法

> 寻找「局部最优解」并尝试叠加成「最优解」

如果问题也存在最优子结构，那么也可以考虑使用贪心解法，如果同时还存在重叠子问题，那么大概率是用动态规划解决。

贪心算法在某些情况下效率可能比「动态规划」还高，因为贪心可以不用「穷举全部」就找到问题的最优解。

1. 贪心算法通常比动态规划更加高效，时间复杂度通常为线性或者线性对数级别。
2. 贪心算法的实现较为简单，通常不需要构建状态转移表或者状态转移方程，因此代码量较少。

**但是要注意：**

1. 贪心算法通常只能解决一部分最优化问题，不能得到全局最优解。
2. 贪心算法通常需要证明贪心策略的正确性，这个过程比较困难，需要具有较高的抽象能力和数学素养。
3. 贪心算法对问题的要求比较高，需要满足“贪心选择性质”和“最优子结构性质”，否则无法使用贪心算法解决问题。

因此，贪心算法通常适用于局部最优解即可满足全局最优的问题，或者作为其他算法的辅助算法，而动态规划通常适用于需要求全局最优解的问题，但是由于时间和空间复杂度的限制，其对于大规模数据的处理能力相对较弱。





### 7.回溯算法

> 试探算法，在做出选择前对下次的可能结果做出试探，如果都不行就回到起点重新试探
>
> 回溯算法就是个多叉树的遍历问题，关键就是在前序遍历和后序遍历的位置做一些操作

涉及的问题：试探的过程是可以通过「剪枝」降低试探次数的

解决一个回溯问题，实际上就是一个「决策树」的遍历过程



#### 回溯的三大要素

- 路径：已经做出的选择
- 选择列表：当前可以做的选择
- 结束条件：也就是到达决策树底层，无法在做出选择



#### 核心思想

> 遇到「全排列问题」一般都先想到暴力递归，回溯求解

**核心就是** **for** **循环里面的递归，在递归调⽤之前「做选择」，在递归调⽤之后「撤销选择」：**

```python
result = []
def backtrack(路径, 选择列表):
	if 满⾜结束条件:
		result.add(路径)
		return
	for 选择 in 选择列表:
		做选择
		backtrack(路径, 选择列表)	
		撤销选择
```

**多叉树的遍历框架：**

```java
void traverse(TreeNode root) {
    for (TreeNode child : root.childern) {
        // 前序遍历需要的操作
        traverse(child);
        // 后序遍历需要的操作
    }
}
```

**写`backtrack`函数时，需要维护走过的「路径」和当前可以做的「选择列表」，当触发「结束条件」时，将「路径」记入结果集**



#### 回溯的时间节点

**前序遍历的代码在进入某一个节点之前的那个时间点执行，后序遍历代码在离开某个节点之后的那个时间点执行**。

**我们只要在递归之前做出选择，在递归之后撤销刚才的选择**，就能正确得到每个节点的选择列表和路径。





#### 注意点

回溯算法的时间复杂度一般都比较高，因为大多数时候都需要遍历整棵「决策树」；

这也是回溯的一个特点，不像动态规划存在重叠的子问题可以优化，回溯往往就是「纯暴力的穷举」；

但是有时候也是可以使用「剪枝」去掉一些不需要遍历就知道一定不合法的分支，以此降低时间复杂度。

使用回溯一般步骤：

1. 确定搜索空间：确定所有可能的解，可以通过枚举或者其他算法来确定。
2. 确定搜索顺序：确定搜索的顺序，可以按照某种规则或者优先级进行搜索。
3. 确定约束条件：确定搜索的约束条件，包括剪枝条件、限制条件等。
4. 确定回溯策略：确定回溯的策略，包括回溯的条件、回溯的顺序等。

回溯算法的优势在于其可以找到问题的所有解，但其劣势也很明显，其时间复杂度非常高，因为回溯算法需要对所有的可能性进行搜索，往往需要进行大量的重复计算。因此，在实际应用中，通常需要采用一些剪枝策略来减少搜索的次数，从而提高回溯算法的效率。

回溯算法的应用非常广泛，可以用于求解组合问题、排列问题、子集问题、图论问题等。在实际应用中，通常需要结合具体问题的特点，对回溯算法进行适当的优化，例如采用记忆化搜索、动态规划等技术来减少搜索次数，提高算法的效率。



#### 小结

某种程度上说，动态规划的暴力求解阶段就是回溯算法。只是有的问题具有重叠子问题性质，可以用 dp table 或者备忘录优化，将递归树大幅剪枝，这就变成了动态规划。

回溯算法一般是针对需要「暴力穷举」又没有「重复子问题」的问题，因此时间复杂度往往都很高。





### 8.模拟算法

>  // TODO 尽可能默认真实情况，使用强大的算力进行预测 









## 其他设计方法

1. 状态机：比如 KMP 算法
2. 循环数组/滚动窗口：优化空间复杂度
3. 滑动窗口：通常用于解决与「子字符串」或者「子数组」的问题
4. 图或者树结构，如果知道起点和终点，是可以尝试从两个节点同时出发降低时间复杂度和空间复杂度的
5. 多指针优化
6. 双指针
7. 快慢指针
8. 左右指针



### 小卡片 – 01

1. **有序-加速：**有序时一般都可以用二分来进行加速，或者使用滑动窗口逐步检测
2. **打表法：**当一个问题入参出参都是正数时，可以使用打表法，即根据一定范围内的输出结果，寻找规律得出数学表达式，这样一般都是最优解，但是注意使用的前提是已经做出了一个不是最优解的版本
3. **数据预处理：**数据预处理，针对频繁查询的数据，使用一定结构提前处理好，需要使用时直接获取
4. **宏观调度：**对于某些问题本身很复杂，但是具有一定规律，比如子过程与整体过程相同，那么可以定义一个宏观调度先完成一个过程，然后调整参数进行下一个过程
5. **子序列与子串：**子序列一般可以断开，子串一般不允许断开





### 大数据题目技巧

一般这些题目都问的比较模糊，需要自己将其精确地抽象出来；往往也会限定资源，此时需要用轮询或者二分等技巧在满足限定的提前下完成数据的遍历与状态的统计

1. 哈希函数可以把数据按照种类均匀分流，典型的问题问法是，给定极小的空间，需要从某个极大的范围中确定想要的结果，此类问题一般都是先找出给定的极小空间可以申请多少用于表示数据状态的小文件或者位图等，确定后再将数据按照某种处理手段，例如取模或者除法等确定数据的范围再将数据放到对应的范围上
2. 布隆过滤器用于集合的建立于查询，并可以节省大量空间，一般该类问题都允许有一定的误差，但这种误差只会指白为黑，不会也不能指黑为白
3. 一致性哈希解决数据服务器的负载管理问题
4. 利用并查集结构做岛问题的并行计算
5. 位图解决某一范围上数字的出现情况，可以节省大量空间
6. 利用分段统计思想可以进一步节省大量空间 
7. 利用堆、外排序可以做多个处理单元的结果合并



### 递归与动态规划

1. 面对具体动态规划特征的问题时，先尝试写出递归版本的暴力解法
2. 暴力解法关注的点有：
   1. 定义递归函数的「参数」与「返回值」的含义，其中可变参数一般是之后动态规划的重要依据，返回值一般代表问题的结果
   2. 确定递归的含义后，需要解决：初始状态时什么，basecase 是什么，什么时候越界，越界返回值怎么决定
   3. 分析普通的中间过程依赖什么
   4. 递归解决依赖调用
3. 写出暴力枚举的解法后，需要尝试「严格表结构」的动态规划解法，如果可变参数是两个，那么表就为二维，依次类推
4. 确定了表的结构后，最先要填上已知的初始状态，有了初始状态后就可以寻找依赖关系，然后逐步将表填写完毕，这样就可以得到最终答案并实现 Coding
5. 这里必须要注意的是，得到暴力解法并开始分析表结构时，就可以不用考虑原题的含义了，表中一切结果一般都可以从暴力递归中推算
6. 实现了严格表结构的 Coding 后可以观察枚举时是否可以减少重复的步骤，可以则使用 dp 数组记录下来进行优化，以此实现动态递归的解法
7. 进阶优化可以从两个方面下手：可变参数的个数与单参数的维度，二者均是越少越好，优化时可以尝试将二维 dp 降至一维节省空间，甚至 可以将一个数组降维成基本类型的参数



### 滑动窗口

> 滑动窗口是一种基于双指针的一种思想，两个指针指向的元素之间形成一个窗口

滑动窗口分为两类：

- 一种是固定大小类的窗口
- 一类是大小动态变化的窗口

滑动窗口初始指针一般是「左闭右开」的，即：[left, right)

滑动窗口一般是由两个「循环」组成：

```java
// 时间复杂度是 O(N)
int left = 0, right = 0;
while (right < s.size()) {
    // 增大窗口
    window.add(s[right]);
    right++;
    while (window needs shrink) {
        // 缩小窗口
        window.remove(s[left]);
        left++;
    }
}
```

**滑动窗口框架：**

```c
/* 滑动窗口算法框架 */
void slidingWindow(string s, string t) {
    unordered_map<char, int> need, window;
    for (char c : t) need[c]++;

    int left = 0, right = 0;
    int valid = 0; 
    while (right < s.size()) {
        // c 是将移入窗口的字符
        char c = s[right];
        // 增大窗口
        right++;
        // 进行窗口内数据的一系列更新
        ...

        /*** debug 输出的位置 ***/
        printf("window: [%d, %d)\n", left, right);
        /********************/

        // 判断左侧窗口是否要收缩
        while (window needs shrink) {
            // d 是将移出窗口的字符
            char d = s[left];
            // 缩小窗口
            left++;
            // 进行窗口内数据的一系列更新
            ...
        }
    }
}
```



### 位运算 -- 不使用判断返回大值

```java
/**
 * 不使用「判断语句」返回两个有符号整数中较大的数字
 * @author gzw
 */
public class GetMax {
    /**
     * 上游函数保证传入的参数 num 只会是 1 或者 0
     * 该函数的功能是将 num 从 1 变为 0，将 0 变为 1
     * 这样做可以得到两个互斥的条件，条件用 1 或 0 的形式代表，意义自行定义
     * @param num 0 或 1
     */
    public int flip(int num) {
        return num ^ 1;
    }

    /**
     * 获取传入的数字的符号
     * 为 1 代表正数，为 0 代表负数
     */
    public int sign(int num) {
        return flip((num >> 31) & 1);
    }

    /**
     * 使用加法与互斥条件返回两数中的大数
     * 但是这个方法是问题的，因为在求差值时可能溢出
     */
    public int getMax1(int a, int b) {
        // 这里是有可能溢出的
        int c = a - b;
        // c 为正数说明 a >= b，此时 sA = 1，sB = 0，否则 a < b，此时 sA = 0，sB = 1
        int sA = sign(c);
        int sB = flip(sA);
        // 因为是互斥条件，所以只可能返回加号两边的其中一项
        return sA * a + sB * b;
    }

    /**
     * 使用加法与互斥条件返回两数中的大数
     * 这个方法就算差值溢出也能返回正确的结果
     */
    public int getMax2(int a, int b) {
        // 这里是有可能溢出的
        int c = a - b;
        // 求出三个值的符号
        int sA = sign(a);
        int sB = sign(b);
        int sC = sign(c);
        // 当 sA 与 sB 符号相同，difSab = 0，sameSab = 1，否则相反
        int difSab = sA ^ sB;
        int sameSab = flip(difSab);
        // 判断是该返回 a 还是 b
        // 加号左边的含义：两个数符号不相同时，如果 sA 是正数，那么就一定返回 a，因为此时 b 为负数一定小，否则返回 b，所以此处直接用 sA 的状态即可
        // 加号右边的含义：两个数符号相同时，绝对不可能溢出，此时直接用 sC 的结果即可
        int returnA = difSab * sA + sameSab * sC;
        // 与返回 A 的条件互斥
        int returnB = flip(returnA);
        // 因为是互斥条件，所以只可能返回加号两边的其中一项
        return returnA * a + returnB * b;
    }

    public static void main(String[] args) {
        System.out.println(Integer.MIN_VALUE);
        System.out.println(Integer.MAX_VALUE);
        int a = 2147483647, b = -2147480000;
        System.out.println(a - b);
        GetMax getMax = new GetMax();
        System.out.println(getMax.getMax1(a, b)); // 返回错误
        System.out.println(getMax.getMax2(a, b)); // 返回正确
    }
}
```



### 位运算 -- 判断是否为 2 或 4 的次幂

```java
public class IsPower {
    /**
     * 判断某个数是否是 2 的次幂
     */
    public boolean is2Power(int n) {
        return (n & (n - 1)) == 0;
    }
    /**
     * 判断某个数是否是 4 的次幂
     * 前提就是该数是 2 的次幂
     */
    public boolean is4Power(int n) {
        // 0x55555555 是 01010101...0101
        return (n & (n - 1)) == 0 && (n & 0x55555555) != 0;
    }
}
```



### 位运算 -- 实现加减乘除

```java
public class ArithmeticOperation {
    /**
     * 前提是 a + b 本身不溢出
     * 溢出是不管是系统还是该方法都不保证计算结果正确
     */
    public int add(int a, int b) {
        int sum = a;
        while (b != 0) {
            // 异或运算本身就是无进位相加
            sum = a ^ b;
            // 与运算能求出进位的结果，当进位为 0 时，此时的 sum 就是最终结果
            b = (a & b) << 1;
            a = sum;
        }
        return sum;
    }
    /**
     * 取反加 1
     */
    public int negNum(int n) {
        return add(~n, 1);
    }
    /**
     * 减法
     */
    public int minus(int a, int b) {
        return add(a, negNum(b));
    }
    /**
     * 乘法
     */
    public int multi(int a, int b) {
        int res = 0;
        while (b != 0) {
            if ((b & 1) != 0) {
                add(res, a);
            }
            a <<= 1;
            // 这里主要要用逻辑右移，否则当 b 是负数时高位会补 1
            b >>>= 1;
        }
        return res;
    }
    /**
     * 判断是否为负数
     */
    public boolean isNeg(int n) {
        return n < 0;
    }
    /**
     * 除法
     */
    public int div(int a, int b) {
        int x = isNeg(a) ? negNum(a) : a;
        int y = isNeg(b) ? negNum(b) : b;
        int res = 0;
        for (int i = 31; i > -1; i = minus(i, 1)) {
            if ((x >> i) >= y) {
                res |= (1 << i);
                x = minus(x, y << i);
            }
        }
        return isNeg(a) ^ isNeg(b) ? negNum(res) : res;
    }
}
```





### 栈与队列互相实现

可以使用「栈」实现「队列」：准备两个栈，需要出栈时就将用户数据的值倒到另外一个辅助栈中，然后依次弹出

或者可以使用「队列」实现「栈」：准备两个队列，需要出队列时，就将需要出队列前的值全部转移到另一个辅助队列中，然后出队列

图的宽度优先遍历需要用队列实现，但是出题可能会让用栈实现，同样地，图的深度优先遍历需要用栈实现，但是出题可能会让队列实现，此时就可以用上面的方法先转换一下



### 动态规划 – 优化 – 01

动态规划的空间压缩，如果更新状态时只需要临近的值，例如当前行只有依赖上一行的值，那么可以将二维压缩成一维，三维同理，如果当前层只依赖上一层的值，那么可以将三维压缩成二维

需要获得最短时间的题可能可以用优先队列进行预处理，之后使用贪心或者动态规划暴力递归求解，找到基础版本后在进行优化

递推式可以通过同一个套路进行优化（斐波那契套路，矩阵快速幂求解），比如可以将斐波那契数列解法从 O(N) 优化到 O(log N) 



### 假设问题

某些问题可能会有些特殊的性质，可以利用这些性质，先假设结果拥有这种性质，然今再模拟整个流程推出过程中必须满足的条件

如何「假设」是动态、贪心、回溯的基础，需要刷的题多才能建立起自己的解题体系

假设的时候需要考虑两种大的情况：「边界情况」和「普通情况」



### 矩阵求解

多维的问题第一点就是考虑能否进行降维

多维矩阵求最值可能可以使用矩阵压缩，就是将多行数据压缩成一行，例如求最大子矩阵的最大累加和，可以将子矩阵每行相加压缩成一行，然后问题就转化成了数组子串最大累加和的问题





### 贪心技巧

假设可能性时，就是在考虑怎么「贪」，这个过程是在「制定规则」，规则之间相互制约不能违反，这样才能将可能性压缩到最少（就是不能想当然地假设，假设后，后面的假设都要受之前规则的制约，这样后面制定的规则也能少一点约束条件）

示例：

> "x..x..x....x.x"，其中 "x" 代表墙，"." 代表空，所有空的位置可以放置一盏灯，所有空间必须都被点亮，而一盏灯的照亮范围是自身的空间加上自身左右两边的空，要求使用最少的灯点亮全部空间 -- 待确认（中级提升班 - 8 开头）

假设需要有「潜台词」，就是代码中没有体现但是一直符合的规则或者说条件，这样才能保证尝试不会互相干扰



### 二叉树 – 技巧 – 01

> 先序、中序 -> 后序，需要找到规律，待补充

完全二叉树的节点个数可以优化到 O((log N) ^ 2)，具体做法是先求出完全二叉树的深度，然后找到右子树的最左节点的是否到达最大深度，这里可以分两种情况讨论，利用递归就可以求解出来



### 动态规划 – 技巧 – 01

 求最大递增子序列的长度

经典的解法是使用动态规划，dp 数组的含义是：到 i 位置的最大递增子序列的长度，完成这个需要从 i 位置往前找比自己小的最大长度的值，也就是最后的时间复杂度会来到 O(N ^2)

可以对上述过程进行加速，加速的点在于，每次往回找的时候都必须再遍历一边，因为 i 位置左边的数不一定是比自己小的，所以每个都要判断一下，换个说法就是左边不具有单调性，由此可以添加一个辅助数组以构建出单调性

具体构建单调性的做法是：将辅助数组下标 i 中的值更新为满足构成长度为 i + 1 的子序列中的最小值（长度都等于 i + 1 的子序列可能有多个，比如 1，3，2，此时该辅助数组下标为 1 的值就应该更新成 2 而不是 3），完成上述行为仅需要：来到 i 位置时，先在辅助数组中「二分查找」比自己大的数，如果找到就覆盖，没有就填入数组的下一个位置，之后就更新 dp 数组，确定此时 dp 数组中 i 位置的值只需要在辅助数组中找比自己小的数有几个即可，之所以可以这样是因为辅助数组经过上述的调整后就变成单调递增的，所以无需此次都比较，而是直接得出答案

上述的过程比较复杂，但是思想是通用的，目的就是为了构造具有单调性的信息，这样就可以消除遍历时的不确定性，所以之后遇到无序且要求最大值时，可以考虑构造出单调的辅助数组

此外：

动态规划的优化方向一般为：

1. 从数据状况入手（例如预处理）
2. 从问题本身入手（例如构造单调递增）





### Base case 不充分

有增有减的递归在 base case 不充分时很可能跑不完，一般画出决策树就很容易看出来

**解决方法：**

- 当递归实在没有限制条件时，可以找出一个平凡解来添加限制，比如某个分支一直是输出结果为偶数的，且需要的结果也是偶数的，那么直接一直使用该分支即可，达到一定阈值再进行其他行为
- 还可以通过问题的具体业务来找出限制条件，但是不通用

一般用这种形式增加条件时，递归的实际含义也需要发生改变，即参数及其含义需要发生改变





### 暴力递归 – 技巧 – 01

暴力递归往往需要从结果出发

先保证思路对，具体细节是 coding 问题，先后思路再验证可行性





### 子串与子数组 – 技巧 – 01

> 每当看到子串或者子数组，就考虑每个位置为结尾的情况是怎么样的，这一点很重要，之后还会经常遇到

一般这种题目往往只需要考虑相邻位置转移到当前位置的可能性

示例：

给定两个字符串 str1 和 str2，再给定三个整数 ic、dc、rc，分别代插入、删除和替换一个字符的代价，返回将 str1 编辑成 str2 的最小代价

【贪心】

贪心有时需要划定一定的范围，再在这个范围内考虑问题（选出最值），同时还需要预处理或者辅助结构

示例：

在一个字符串中，每种字符都必须保留一个，并且顺序不能乱，要求最后的结果字典序最小并返回

需要建立一个词频表，记录每一个字符出现的次数

每到一个字符，相应的次数减1，直到减到0为止，此时需要从当前为止的左边选出一个码值最小的字符，该字符就是需要保留的（此处就是在一定范围内贪），然后再删除掉选出的该字符左边的部分，因为已经选了到目前为止最小的，所以选出的该字符左边的已经没用了；保留下来的部分再删除所有该字符（比如选出了a，那么就删掉a左边的完全，保留下来的子串后续可能还有a，不管，直接删除掉子串中的全部a），对得到的子串再进行递归，贪出剩下应该保留的字符

```java
public class MinSubStr {
    public String minSubStr(String str) {
        Map<Character, Integer> map = new HashMap();
        for (int i = 0; i < str.length(); i++) {
           char ch = str.charAt(i);
           if (map.getOrDefault(ch, 0) != 1) {
               map.putIfAbsent(ch, 1);
           } else {
               map.put(ch, map.get(ch) + 1);
           }
        }
        return remove(str, map);
    }

    public String remove(String str, Map<Character, Integer> map) {
        if (str == null || str.length() < 2) {
            return "";
        }
        int minIndex = 0;
        for (int i = 0; i < str.length(); i++) {
            char ch = str.charAt(i);
            map.put(ch, map.get(ch) - 1);
            if (map.get(ch) != 0) {
                break;
            } else {
               minIndex = str.charAt(minIndex) > str.charAt(i) ? i : minIndex;
            }
        }
        return str.charAt(minIndex) + remove(str.substring(minIndex + 1).replaceAll(String.valueOf(str.charAt(minIndex)), ""), map);
    }
}
```





### 舍弃可能性 -- 构造一个答案

给定一个数组，求如果排序之后，相邻两数的最大差值。要求时间复杂度为 O(N)，且要求不能使用「非基于比较的排序」

要多一个桶

三个数组存储必要信息

原理：

多一个桶的目的是设立一个「平凡解」，这个平凡解是较为优良的答案，可以解决（舍弃）大部分一定不是答案的解，但是未必是最终的答案

比如每个桶的容量是10，因为多出一个桶，所以必定有一个桶是空的，而空桶左右两侧的差值一定大于空桶内部的最大差值，所以这个空桶就限制了最终的答案不可能小于10

平凡解优化流程，如何优化？舍弃了可能性



多出一个桶能不能舍弃？

显然不能，因为多一个桶就是为了保证：相邻桶的差值必定大于桶内的差值，如果舍弃这个空桶，就可能出现桶内差值大于相邻桶之间的值，这时就必须考虑桶内的情况（需要排序），这样也就没有必要再分桶了



优化：

因为只需要计算一个桶中的最大值和最小值，所以没有必要每个桶都开辟 10 的空间，只需要用两个数组分别记录最大值和最小值即可，数组下标就是第几个桶，另外还需要一个数组记录哪个位置从始至终都没有进来过数字

这样最后不需要排序，也能算出排序后相邻数的最大差值





### 舍弃可能性 -- 假设一个答案

给出 n 个数字，问最多有多少个不重叠的划分（非空区间），使得每个区间内数字的 xor（异或）都等于 0

异或操作其中一个理解就是无进位相加，做这题用这个理解比较好判断

普通的 i 位置有两种可能性：

1. 以 i 结尾的划分，异或结果不是 0，此时这个划分没有 i 位置和有 i 位置都是等效的，dp[i] = dp[i - 1] 即可
2. 以 i 结尾的划分，异或结果是 0，此时需要假设：

假设以 i 位置结尾的一个「最优划分」中（该划分异或和为 0），k 位置是该划分的开头

性质：

那么这个 k 位置就是离 i 位置最近的使得该划分异或和为零的位置（如果不是最近，也就不是最优解了） 

同时，这也代表着 k - 1 位置的值和 i 位置的值是一样的（注意我们现在讨论的前提是以 i 结尾的划分，异或结果是 0）



如何找到这个最近 k 位置？

需要准备：

1. dp 数组，含义为：以 i 位置值结尾的前缀中异或和最优的总数
2. 一个变量（xor）：记录着一直异或到 i 位置的值，初始值为 0（这个变量的目的就是判断以 i 结尾的划分，异或结果是不是 0）
3. 索引表：键为当前 xor 的值，值为距离上一次出现 i 位置值的位置（k 位置）



为什么这样准备？

dp 数组这样定义后，经过一定流程，最后一个必定是答案，问题这个流程是怎么样的

变量 xor 一直累积异或值，一是为了压缩前面的状态，因为前面的数本来就是要一直异或的，记录下来后 i 位置前面就相当于只有一个数了；二是这个异或值就索引表中的键，这样就很容易找到 k 位置

索引表是为了不断更新并且可以找到 k 位置，最近的这个 k 位置就是上一次 i 位置的值出现的位置，为什么是这样的？

假设数组是：3，2，1

来到 arr[2] ：1 时，前面 3，2 已经异或，相当于压缩成了 1，即现在数组可以想象成：1，1，那既然压缩了，我们怎么获取前一个 1 的位置呢？就是索引表！

回到正题，为什么要找的 k 位置的值和当前 i 位置的值是一样的？

因为 1 .... 1，如果这是一个异或为 0 的区域，那么直接取前面的 0 就好了，后面的不需要，如果需要后面的就说明前面的已经构成了最优，只能考虑后续的 1



为什么 eor 的值就是索引表中的键？直接看例子：

假设数组为：3，2，1，4，0，那么索引表的情况变化就是：

1. arr[]：空，xor：0，key：0，value：-1（初始化）
2. arr[0]：3，xor：3，key：3，value：0，dp[i]：0（初始化）
3. arr[1]：2，xor：1，key：1，value：1，dp[i]：dp[i - 1]（索引表中没有出现过，说明之前没有相同的数，只可能是可能性 1 的答案，此时 dp[i] 直接拷贝 dp[i - 1] 的值）
4. arr[2]：1，xor：0，key：0，value：2，dp[i]：max(dp[i], dp[i - 1])（取可能性1、2中的最大值）补充：这里 value 从 -1 变成 2 是因为，前面的所有数 3，2，1 都已经异或成了 0，看成一个整体相当于压缩成了 0，所以距离这个 0 最近的位置就变成了 2
5. arr[3]：4，xor：4，key：4，value：3，dp[i]：dp[i - 1]
6. arr[4]：0，xor：4，key：4，value：3，max(dp[i], dp[i - 1])（索引表中出现了，说明 3 + 1 ~ 4，即 4 ~ 4 是一个划分，0 ~ 3 是一个划分，也就是此时可能性 2 的值是 dp[3] + 1 = 2，可能性 1 的值是 dp[3] = 1，所以最后的结果是 2）

```java
/**
 * 给出 n 个数字，问最多有多少个不重叠的划分（非空区间），使得每个区间内数字的 xor（异或）都等于 0
 */
public class MostXor {
    public int mostEor(int[] arr) {
        int xor = 0;
        int[] dp = new int[arr.length];
        Map<Integer, Integer> map = new HashMap<>();
        map.put(0, -1);
        for (int i = 0; i < arr.length; i++) {
            xor ^= arr[i];
            if (map.containsKey(xor)) {
                int pre = map.get(xor);
                dp[i] = pre == -1 ? 1 : dp[pre] + 1;
            }
            if (i > 0) {
                dp[i] = Math.max(dp[i], dp[i - 1]);
            }
            map.put(xor, i);
        }
        return dp[arr.length - 1];
    }
}
```





### 斜率优化

当临近的上一行有枚举行为时，可以使用当前临近的值代替





### 整体中位数求解

两个数组长度一样，怎么找到整体的上中位数？（比如两个数组长度都为 4，怎么确定整体的第 4 小）

假设两数组「排序」后有：

当长度为偶数时：

arrA = [a, b, c, d]

arrB = [a', b', c', d']

1. 如果 b = b'，那么 b 一定是上中位数
2. 如果 b > b'，那么 c, d, a', b' 一定不会是上中位数，又因为 a, b, c', d'，长度相同，再次求这两个子数组的上中位数（以此类推），这就是原数组的上中位数（子问题的上中位数就是原问题的上中位数）

当长度为奇数时：

arrA = [a, b, c, d, e]

arrB = [a', b', c', d', e']

1. 如果 c = c'，那么 c 一定是上中位数
2. 如果 c > c'，那么 c, d, e, a', b' 一定不会是上中位数，但是由于剩下的两个子数组长度不一样，所以不能递归求解，此时只需要验证一下 c' 是否大于 b，如果是那么 c’ 就一定是上中位数，如果不是那就直接排除掉 c'，此时两个子数组的长度又相同了

等长有序，数组上中位数具有传递性



上面的结论也可以用于两个数组长度不等：

给定两个一维 int 数组 A 和 B

其中：A 的长度为 m，B 的长度为 n，元素从小到大排好序。

希望从 A 和 B 中找出最大的 k 个数字，要求使用尽量小的比较次数

普通解法：

两个指针依次比较（最慢）

二分（较快）

最优解：

假设两个有序数组长度分别为：10 和 17

1. 如果 1 <= k <= 10，那么从两个数组中分别取前 k 个数（两个长度为 k 的子数组），求上中位数就是最终解
2. 如果 10 < k <= 17（最后讲，先看下面一段的范围）
3. 如果 17 < k <= 27：

比如有：

A: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10

B: 1', 2', 3', 4', 5', 6', 7', 8', 9, 10'', 11', 12', 13', 14', 15', 16', 17'

如果求的 k = 23，那么有：

A 中前 23 - 17 - 1 = 5 个必定不可能是，同理，B 中前 23 - 10 - 1 = 12 个必定不可能是

但注意，这样一共排除掉了：12 + 5 = 17 个数，还需要 6 个数，但是剩下的是子数组求出来的是第 5 位，所以不能直接求中位数，此时需要多两次比较：

1. 如果 6 > 17'，那么 6 一定是上中位数，不是就淘汰 6，继续
2. 如果 13‘ > 10，那么 13' 一定是上中位数，不是就淘汰 13'，继续
3. 最后可以发现，一共排除掉了 17 + 2 = 19，而剩下的子数组正好能够求出第 4 位，所以直接求子数组的中位数



如果 10 < k <= 17， 比如 k = 15

那么 A 中的数全部有可能

B 中的数前 15 - 10 - 1 = 4 不可能是，后 17 - 15 = 2 个不可能是，剩下的全部有可能

此时 A 还剩 10 个，但是 B 中还剩 11 个

此时看 5‘ 是否大于 10，如果大于则 5' 就是，直接返回，如果不是就淘汰

此时 一共排除了 4 + 2 + 1 = 7，还需要 5 个，剩下的子数组正好可以求出




