---
title： "Lucene"
shortTitle： "A-Lucene"
description： "Lucene"
icon： ""
author： 
  name： gzw
  url： 
  email： 1627121193@qq.com
isOriginal： false
date： 2022-04-23
category： 
- "中间件"
- "elasticsearch"
tag：
- "中间件"
- "elasticsearch"
sticky： 1
star： false
article： true
timeline： true
dir：
  text： "Lucene"
  icon： ""
  collapsible： true
  index： true
  comment： true
headerDepth： 3
index： true
order： 2
copy：
  triggerWords： 100
  disableCopy： false
  disableSelection： false
feed：
  title： "Lucene"
  description： "Lucene"
  author：
    name： gzw
    email： 1627121193@qq.com
---







# Lucene

[[toc]]





## 基础知识

### 核心概念

- 文档（document）：索引和搜索的数据载体，包含一个或者多个字段，存放要写入索引或从索引搜索出来的数据
- 字段（field）：文档的一个片段，包括两个部分：字段名称和内容
- 词项（term）：搜索时的一个单位，代表文本中的某个词
- 词条（token）：词项在字段中的一次出现，包括词项的文本、开始和结束的位移以及类型

索引组织的结构为：倒排索引



### 分析器

1. 分词器
2. 过滤器
   1. 小写过滤
   2. ASCII过滤
   3. 同义词过滤
   4. 多语言词干还原过滤
3. 字符映射

重点：

- Lucene可以对不同的字段使用不同的分析器
- 索引期和检索期的文本分析要采用相同的分析器，只有查询分析出来的此项与索引中词项相同才会返回文档集



### 查询

一次查询会被分为：词项和操作符

词项可以是单个词也可以是短语

查询可以包含布尔操作符，用于连接多个词项构成从句，布尔操作符包括：

- `AND`
- `OR`
- `NOT`
- `+`
- `-`

可以使用「词项修饰符」修改查询对象的词项：

- `?`
- `*`

注意：通配符不要作为词项的第一个字出现，会影响性能

模糊搜索使用`~`紧跟整数值

特殊字符转义使用反斜杠`\`



### 查询改写

可以对任意多词项查询使用`rewrite`参数来控制查询改写，`rewrite`参数的配置项有：

- `scoring_boolean`：将每个生成的词项转换为布尔查询中的一个或从句，这样比较消耗CPU资源，并且布尔查询默认为1024个从句。
- `constant_score_boolean`：与上述类似，但是CPU消耗较低，该过程不计算每个从句的得分，每个从句得到一个与查询权重相同的常数得分，默认情况下等于1。

- `constant_score_filter`：通过遍历每一个词项来创建一个私有的过滤器，标记跟每个词项相关的文档，命中的文档被赋予一个跟查询权重相同的常量得分，当命中词项数或者文档数较大时，会比上述两种方法更快。
- `top_terms_N`：将每个生成的词项转化为布尔查询中的一个或从句，并保存计算出来的得分，该方法只保留最佳的前N个词项，从而避免超出布尔从句数的限制。
- `top_terms_boost_N`：与上述类似，但是该选项产生的从句类型为常量得分查询，得分为从句的权重。



### 评分

> 评分是一个用户刻画与查询匹配程度的参数

Lucene的默认评分机制为：TF/IDF（词频/逆文档频率）。

为了计算文档得分，需要考虑下面的因子：

- 文档权重
- 字段权重
- 协调因子：文档命中的词项越多，得分越高
- 逆文档频率：逆文档频率越低表示该词项越罕见，会利用该因子为包含罕见词项的文档加权
- 长度范数：每个字段的基于词项个数的归一化因子，一个字段包含的词项数越多，该银子的权重越低
- 词频：词项在文档中出现的次数，词频越高，文档得分越高
- 查询范数：基于查询的归一化因子，等于查询中词项的权重平方和，使得不同查询的得分能够相互比较

TF/IDF理论评分公式（该公式结合布尔检索模型和向量空间检索模型）：
$$
s c o r e(q,d)=c o o r d(q,d)*q u e r y B o o s t(q)*\frac{V(q)*V(d)}{\left|V(q)\right|}*l e n g t h N o r m(d)*d o c B o o s t(d)
$$
Lucene的TF/IDF真实评分公式：
$$
s c o r e(q,d)=c o o r d(q,d)*q u e r y N o r m(q)*\sum_{t i m\ q}\left(t/(t,i n\ d)*i d f(t)^{2}*b o o s t(t)*n o r m(t,d)\right)
$$
该公式是一个关于查询q和文档d的函数，求和公式中每个加数由：词频、逆文档频率、词项权重、范数连乘得到。

从公式中可以发现：

- 越多罕见词项被匹配上，文档得分越高
- 文档字段越短（包含更少的词项），文档得分越高
- 权重越高（不论是索引期还是查询期的权重），文档得分越高

:::info 说明

Lucene4.0之后用户可以改变默认的基于TF/IDF的评分算法，并且提供了更多的相似度模型，从而允许我们采用不同的评分公式

:::



### 二次评分

二次评分是指重新计算查询返回文档中指定个数文档的得分（在原始查询返回的文档的子集上做计算耗时会短一些），ES会截取查询返回分档的前N个，并使用预定义的二次评分方法重新计算得分。

在rescore对象中的查询对象中，必须配置下面这些参数：

- `window size`：窗口大小，该参数默认设置为from和size参数值之和。它提供了之前提到的N个文档的相关信息。该参数值指定了每个分片上参与二次评分的文档个数。
- `query_weight`：查询权重值，默认等于1，原始查询的得分与二次评分的得分相加之前将乘以该值。
- `rescore_query_weight`：二次评分查询的权重值，默认等于1，二次评分查询的得分在与原始查询得分相加之前，将乘以该值。
- `rescore_mode`：二次评分的模式，默认设置为total,ElasticSearch0.90.3引入了该参数（之前版本中类似的行为，该参数只能设置为total），它定义了二次评分中文档得分的计算方式，可用的选项有total、max、min、avg和multiply。当我们设置该参数值为total时，文档得分为原始查询得分与二次评分得分之和。当该参数值设置为max,文档得分为原始查询得分与二次评分得分中的最大值。与max选项类似，当该参数值设置为mi时，文档得分为两次查询得分中的最小值。以此类推，参数值为avg时，文档得分为两次查询得分的平均值。当参数值为multiply时，文档得分为两次查询得分的乘积。



### 相似度模型

- Okapi BM:25模型：这是一种基于概率模型的相似度模型，可用于估算文档与给定查询匹配的概率。为了在ElasticSearch中使用它，需要使用该模型的名字：BM25。一般来说，Okapi BM25模型在短文本文档上的效果最好，因为这种场景中重复词项对文档的总体得分损害较大。
- 随机偏离（Divergence from randomness）模型：这是一种基于同名概率模型的相似度模型。为了在ElasticSearch中使用它，需要使用该模型的名字：DFR。一般来说，随机偏离模型在类似自然语言的文本上效果较好。
- 基于信息的（Information based）模型：这是最后一个新引入的相似度模型，与随机偏离模型类似。为了在ElasticSearch中使用它，需要使用该模型的名字：IB。同样，IB模型也在类似自然语言的文本上拥有较好的效果。



### 编解码器

Lucene4.0允许用户改变索引文件的编码方式。

可用的倒排表格式：

- `default`：当没有显式配置时，倒排表使用该格式。该格式提供了存储字段（storedfield）和词项向量压缩功能。
- `pulsing`：该编解码器将高基（high cardinality）字段e中的倒排表编码为词项数组，这会减少Lucene在搜索文档时的查找操作。使用该编解码器，可以提高在高基字段中的搜索速度。
- `direct`：该编解码器在读索引阶段将词项载人词典，且词项在内存中为未压缩状态。该编解码器能提升常用字段的查询性能，但也需要谨慎使用，由于词项和倒排表数组都需要存储在内存中，从而导致它非常消耗内存。
- `memory`：顾名思义，该编解码器将所有数据写人磁盘，而在读取时则使用ST（Finite State Transducers）结构直接将词项和倒排表载入内存。
- `bloom_default`：是default编解码器的一种扩展，即在default编解码器处理基础上又加人了bloom filter的处理，且bloom filter相关数据会写人磁盘中。当读人索引时，bloom filter相关数据会被读入内存，用于快速判断某个特定值是否存在。该编解码器在处理主键之类的高基字段时非常有用。
- `bloom_pulsing`：它是pulsing编解码器的扩展，在pulsing编解码器处理基础上又加人了bloom filter的处理。

